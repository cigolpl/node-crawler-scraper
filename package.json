{
  "name": "node-crawler-scraper",
  "version": "1.0.1",
  "description": "Simple and powerful crawler. It scraps content and collects links from websites using request or phantomjs. The whole magic and simplicity is behind configuration.",
  "main": "./lib/crawler.js",
  "keywords": [
    "scraper",
    "scraping",
    "phantomjs",
    "cache",
    "crawling",
    "queue",
    "nodejs",
    "spider",
    "jquery",
    "crawler"
  ],
  "directories": {
    "test": "tests"
  },
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "author": "Mateusz Rzepa",
  "dependencies": {
    "async": "^1.4.2",
    "bluebird": "^2.10.2",
    "cheerio": "^0.19.0",
    "iconv-lite": "^0.4.13",
    "lodash": "^3.10.1",
    "make-url": "0.0.1",
    "nock": "^2.15.0",
    "node-horseman": "^2.6.0",
    "request": "^2.64.0",
    "underscore": "^1.8.3",
    "url": "^0.11.0",
    "urlencode": "^1.1.0"
  },
  "devDependencies": {
    "grunt": "^0.4.5",
    "grunt-mocha-test": "^0.12.7",
    "grunt-nodemon": "^0.4.0",
    "mocha": "^2.3.3",
    "should": "^4.6.5"
  },
  "license": "MIT"
}
